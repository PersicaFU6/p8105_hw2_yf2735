p8105_hw2_yf2735
================
Yujing FU
2024-09-26

    ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
    ## ✔ dplyr     1.1.4     ✔ readr     2.1.5
    ## ✔ forcats   1.0.0     ✔ stringr   1.5.1
    ## ✔ ggplot2   3.5.1     ✔ tibble    3.2.1
    ## ✔ lubridate 1.9.3     ✔ tidyr     1.3.1
    ## ✔ purrr     1.0.2     
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()
    ## ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors

## problem 1

## problem 2

``` r
library(readxl)
library(dplyr)
library(janitor)
```

    ## 
    ## Attaching package: 'janitor'

    ## The following objects are masked from 'package:stats':
    ## 
    ##     chisq.test, fisher.test

Mr. Trash Wheel dataset

``` r
mr_trash_df = 
  read_excel("data/202409 Trash Wheel Collection Data.xlsx", sheet = "Mr. Trash Wheel", skip = 1) |> 
  select(-starts_with("...")) |> 
  janitor::clean_names() |>
  filter(!is.na(dumpster)) |> 
  mutate(sports_balls = as.integer(round(sports_balls, 0)))
```

    ## New names:
    ## • `` -> `...15`
    ## • `` -> `...16`

``` r
mr_trash_df
```

    ## # A tibble: 651 × 14
    ##    dumpster month year  date                weight_tons volume_cubic_yards
    ##       <dbl> <chr> <chr> <dttm>                    <dbl>              <dbl>
    ##  1        1 May   2014  2014-05-16 00:00:00        4.31                 18
    ##  2        2 May   2014  2014-05-16 00:00:00        2.74                 13
    ##  3        3 May   2014  2014-05-16 00:00:00        3.45                 15
    ##  4        4 May   2014  2014-05-17 00:00:00        3.1                  15
    ##  5        5 May   2014  2014-05-17 00:00:00        4.06                 18
    ##  6        6 May   2014  2014-05-20 00:00:00        2.71                 13
    ##  7        7 May   2014  2014-05-21 00:00:00        1.91                  8
    ##  8        8 May   2014  2014-05-28 00:00:00        3.7                  16
    ##  9        9 June  2014  2014-06-05 00:00:00        2.52                 14
    ## 10       10 June  2014  2014-06-11 00:00:00        3.76                 18
    ## # ℹ 641 more rows
    ## # ℹ 8 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, glass_bottles <dbl>, plastic_bags <dbl>,
    ## #   wrappers <dbl>, sports_balls <int>, homes_powered <dbl>

Professor Trash Wheel dataset

``` r
prof_trash_df = 
  read_excel("data/202409 Trash Wheel Collection Data.xlsx", sheet = "Professor Trash Wheel", skip = 1) |> 
  select(-starts_with("...")) |> 
  janitor::clean_names() |>
  filter(!is.na(dumpster)) |> 
  mutate(year = as.character(year))
prof_trash_df
```

    ## # A tibble: 119 × 13
    ##    dumpster month    year  date                weight_tons volume_cubic_yards
    ##       <dbl> <chr>    <chr> <dttm>                    <dbl>              <dbl>
    ##  1        1 January  2017  2017-01-02 00:00:00        1.79                 15
    ##  2        2 January  2017  2017-01-30 00:00:00        1.58                 15
    ##  3        3 February 2017  2017-02-26 00:00:00        2.32                 18
    ##  4        4 February 2017  2017-02-26 00:00:00        3.72                 15
    ##  5        5 February 2017  2017-02-28 00:00:00        1.45                 15
    ##  6        6 March    2017  2017-03-30 00:00:00        1.71                 15
    ##  7        7 April    2017  2017-04-01 00:00:00        1.82                 15
    ##  8        8 April    2017  2017-04-20 00:00:00        2.37                 15
    ##  9        9 May      2017  2017-05-10 00:00:00        2.64                 15
    ## 10       10 May      2017  2017-05-26 00:00:00        2.78                 15
    ## # ℹ 109 more rows
    ## # ℹ 7 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, glass_bottles <dbl>, plastic_bags <dbl>,
    ## #   wrappers <dbl>, homes_powered <dbl>

Gwynnda Trash Wheel

``` r
gwynnda_trash_df = 
  read_excel("data/202409 Trash Wheel Collection Data.xlsx", sheet = "Gwynnda Trash Wheel", skip = 1) |> 
  select(-starts_with("...")) |> 
  janitor::clean_names() |>
  filter(!is.na(dumpster)) |> 
  mutate(year = as.character(year))
gwynnda_trash_df
```

    ## # A tibble: 263 × 12
    ##    dumpster month  year  date                weight_tons volume_cubic_yards
    ##       <dbl> <chr>  <chr> <dttm>                    <dbl>              <dbl>
    ##  1        1 July   2021  2021-07-03 00:00:00        0.93                 15
    ##  2        2 July   2021  2021-07-07 00:00:00        2.26                 15
    ##  3        3 July   2021  2021-07-07 00:00:00        1.62                 15
    ##  4        4 July   2021  2021-07-16 00:00:00        1.76                 15
    ##  5        5 July   2021  2021-07-30 00:00:00        1.53                 15
    ##  6        6 August 2021  2021-08-11 00:00:00        2.06                 15
    ##  7        7 August 2021  2021-08-14 00:00:00        1.9                  15
    ##  8        8 August 2021  2021-08-16 00:00:00        2.16                 15
    ##  9        9 August 2021  2021-08-16 00:00:00        2.6                  15
    ## 10       10 August 2021  2021-08-17 00:00:00        3.21                 15
    ## # ℹ 253 more rows
    ## # ℹ 6 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, plastic_bags <dbl>, wrappers <dbl>,
    ## #   homes_powered <dbl>

Combing three datasets

``` r
all_trash_wheels = bind_rows(
  mr_trash_df |>  mutate(trash_wheel_name = "Mr. Trash Wheel"),
  prof_trash_df |>  mutate(trash_wheel_name = "Professor Trash Wheel"),
  gwynnda_trash_df |>  mutate(trash_wheel_name = "Gwynnda Trash Wheel")
) |> 
  select(trash_wheel_name, everything())
all_trash_wheels
```

    ## # A tibble: 1,033 × 15
    ##    trash_wheel_name dumpster month year  date                weight_tons
    ##    <chr>               <dbl> <chr> <chr> <dttm>                    <dbl>
    ##  1 Mr. Trash Wheel         1 May   2014  2014-05-16 00:00:00        4.31
    ##  2 Mr. Trash Wheel         2 May   2014  2014-05-16 00:00:00        2.74
    ##  3 Mr. Trash Wheel         3 May   2014  2014-05-16 00:00:00        3.45
    ##  4 Mr. Trash Wheel         4 May   2014  2014-05-17 00:00:00        3.1 
    ##  5 Mr. Trash Wheel         5 May   2014  2014-05-17 00:00:00        4.06
    ##  6 Mr. Trash Wheel         6 May   2014  2014-05-20 00:00:00        2.71
    ##  7 Mr. Trash Wheel         7 May   2014  2014-05-21 00:00:00        1.91
    ##  8 Mr. Trash Wheel         8 May   2014  2014-05-28 00:00:00        3.7 
    ##  9 Mr. Trash Wheel         9 June  2014  2014-06-05 00:00:00        2.52
    ## 10 Mr. Trash Wheel        10 June  2014  2014-06-11 00:00:00        3.76
    ## # ℹ 1,023 more rows
    ## # ℹ 9 more variables: volume_cubic_yards <dbl>, plastic_bottles <dbl>,
    ## #   polystyrene <dbl>, cigarette_butts <dbl>, glass_bottles <dbl>,
    ## #   plastic_bags <dbl>, wrappers <dbl>, sports_balls <int>, homes_powered <dbl>

## Trash Wheel Data Summary

This combined dataset `all_trash_wheels` has 1033 observations.

Key variables are listed as follows: The name of the trash wheel:
`trash_wheel_name`, e.g. Mr. Trash Wheel.

The date:`date`, e.g.2014-05-16.

The weight of trash collected(tons): `weight_tons`,e.g. 4.31.

The volume of trash collected(cubic):`volume_cubic_yards`, e,g, 18.

The amount of plastic bottles it collected: `plastic_bottles`, e.g.1450.

The amount of polystyrene it collected: `polystyrene`, e.g. 1820.

The total weight of trash collected by Professor Trash Wheel is 246.74
tons.

The total number of cigarette butts collected by Gwynnda in June of 2022
is 1.812^{4}

## problem 3

``` r
library(readr)
library(janitor)
library(dplyr)

bakers_df =
  read_csv("data/gbb_datasets/bakers.csv") |> 
  janitor::clean_names() |> 
  mutate(baker = word(baker_name, 1, sep = " "),
         series = as.numeric(series)) 
```

    ## Rows: 120 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (3): Baker Name, Baker Occupation, Hometown
    ## dbl (2): Series, Baker Age
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
bakers_df
```

    ## # A tibble: 120 × 6
    ##    baker_name       series baker_age baker_occupation             hometown baker
    ##    <chr>             <dbl>     <dbl> <chr>                        <chr>    <chr>
    ##  1 Ali Imdad             4        25 Charity worker               Saltley… Ali  
    ##  2 Alice Fevronia       10        28 Geography teacher            Essex    Alice
    ##  3 Alvin Magallanes      6        37 Nurse                        Brackne… Alvin
    ##  4 Amelia LeBruin       10        24 Fashion designer             Halifax  Amel…
    ##  5 Andrew Smyth          7        25 Aerospace engineer           Derby /… Andr…
    ##  6 Annetha Mills         1        30 Midwife                      Essex    Anne…
    ##  7 Antony Amourdoux      9        30 Banker                       London   Anto…
    ##  8 Beca Lyne-Pirkis      4        31 Military Wives' Choir Singer Aldersh… Beca 
    ##  9 Ben Frazer            2        31 Graphic Designer             Northam… Ben  
    ## 10 Benjamina Ebuehi      7        23 Teaching assistant           South L… Benj…
    ## # ℹ 110 more rows

``` r
bakes_df =
  read_csv("data/gbb_datasets/bakes.csv") |> 
  janitor::clean_names() |> 
  mutate(series = as.numeric(series),
         episode = as.numeric(episode))
```

    ## Rows: 548 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (3): Baker, Signature Bake, Show Stopper
    ## dbl (2): Series, Episode
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
bakes_df
```

    ## # A tibble: 548 × 5
    ##    series episode baker     signature_bake                          show_stopper
    ##     <dbl>   <dbl> <chr>     <chr>                                   <chr>       
    ##  1      1       1 Annetha   "Light Jamaican Black Cakewith Strawbe… Red, White …
    ##  2      1       1 David     "Chocolate Orange Cake"                 Black Fores…
    ##  3      1       1 Edd       "Caramel Cinnamon and Banana Cake"      N/A         
    ##  4      1       1 Jasminder "Fresh Mango and Passion Fruit Humming… N/A         
    ##  5      1       1 Jonathan  "Carrot Cake with Lime and Cream Chees… Three Tiere…
    ##  6      1       1 Lea       "Cranberry and Pistachio Cakewith Oran… Raspberries…
    ##  7      1       1 Louise    "Carrot and Orange Cake"                Never Fail …
    ##  8      1       1 Mark      "Sticky Marmalade Tea Loaf"             Heart-shape…
    ##  9      1       1 Miranda   "Triple Layered Brownie Meringue Cake\… Three Tiere…
    ## 10      1       1 Ruth      "Three Tiered Lemon Drizzle Cakewith F… Classic Cho…
    ## # ℹ 538 more rows

``` r
results_df =
  read_csv("data/gbb_datasets/results.csv", skip=2) |> 
  janitor::clean_names() |> 
  mutate(series = as.numeric(series),
         episode = as.numeric(episode))
```

    ## Rows: 1136 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (2): baker, result
    ## dbl (3): series, episode, technical
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
results_df
```

    ## # A tibble: 1,136 × 5
    ##    series episode baker     technical result
    ##     <dbl>   <dbl> <chr>         <dbl> <chr> 
    ##  1      1       1 Annetha           2 IN    
    ##  2      1       1 David             3 IN    
    ##  3      1       1 Edd               1 IN    
    ##  4      1       1 Jasminder        NA IN    
    ##  5      1       1 Jonathan          9 IN    
    ##  6      1       1 Louise           NA IN    
    ##  7      1       1 Miranda           8 IN    
    ##  8      1       1 Ruth             NA IN    
    ##  9      1       1 Lea              10 OUT   
    ## 10      1       1 Mark             NA OUT   
    ## # ℹ 1,126 more rows

Use antijoin to compare datasets

``` r
anti_join(bakes_df, results_df, by = c("series", "episode", "baker"))
```

    ## # A tibble: 8 × 5
    ##   series episode baker    signature_bake                            show_stopper
    ##    <dbl>   <dbl> <chr>    <chr>                                     <chr>       
    ## 1      2       1 "\"Jo\"" Chocolate Orange CupcakesOrange and Card… Chocolate a…
    ## 2      2       2 "\"Jo\"" Caramelised Onion, Gruyere and Thyme Qui… Raspberry a…
    ## 3      2       3 "\"Jo\"" Stromboli flavored with Mozzarella, Ham,… Unknown     
    ## 4      2       4 "\"Jo\"" Lavender Biscuits                         Blueberry M…
    ## 5      2       5 "\"Jo\"" Salmon and Asparagus Pie                  Apple and R…
    ## 6      2       6 "\"Jo\"" Rum and Raisin Baked Cheesecake           Limoncello …
    ## 7      2       7 "\"Jo\"" Raspberry & Strawberry Mousse Cake        Pain Aux Ra…
    ## 8      2       8 "\"Jo\"" Raspberry and Blueberry Mille Feuille     Mini Victor…

``` r
anti_join(results_df, bakes_df, by = c("series", "episode", "baker"))
```

    ## # A tibble: 596 × 5
    ##    series episode baker    technical result
    ##     <dbl>   <dbl> <chr>        <dbl> <chr> 
    ##  1      1       2 Lea             NA <NA>  
    ##  2      1       2 Mark            NA <NA>  
    ##  3      1       3 Annetha         NA <NA>  
    ##  4      1       3 Lea             NA <NA>  
    ##  5      1       3 Louise          NA <NA>  
    ##  6      1       3 Mark            NA <NA>  
    ##  7      1       4 Annetha         NA <NA>  
    ##  8      1       4 Jonathan        NA <NA>  
    ##  9      1       4 Lea             NA <NA>  
    ## 10      1       4 Louise          NA <NA>  
    ## # ℹ 586 more rows

``` r
anti_join(bakers_df, bakes_df, by = c("series", "baker"))
```

    ## # A tibble: 26 × 6
    ##    baker_name          series baker_age baker_occupation          hometown baker
    ##    <chr>                <dbl>     <dbl> <chr>                     <chr>    <chr>
    ##  1 Alice Fevronia          10        28 Geography teacher         Essex    Alice
    ##  2 Amelia LeBruin          10        24 Fashion designer          Halifax  Amel…
    ##  3 Antony Amourdoux         9        30 Banker                    London   Anto…
    ##  4 Briony Williams          9        33 Full-time parent          Bristol  Brio…
    ##  5 Dan Beasley-Harling      9        36 Full-time parent          London   Dan  
    ##  6 Dan Chambers            10        32 Support worker            Rotherh… Dan  
    ##  7 David Atherton          10        36 International health adv… Whitby   David
    ##  8 Helena Garcia           10        40 Online project manager    Leeds    Hele…
    ##  9 Henry Bird              10        20 Student                   Durham   Henry
    ## 10 Imelda McCarron          9        33 Countryside recreation o… County … Imel…
    ## # ℹ 16 more rows

``` r
anti_join(bakes_df, bakers_df, by = c("series", "baker"))
```

    ## # A tibble: 8 × 5
    ##   series episode baker    signature_bake                            show_stopper
    ##    <dbl>   <dbl> <chr>    <chr>                                     <chr>       
    ## 1      2       1 "\"Jo\"" Chocolate Orange CupcakesOrange and Card… Chocolate a…
    ## 2      2       2 "\"Jo\"" Caramelised Onion, Gruyere and Thyme Qui… Raspberry a…
    ## 3      2       3 "\"Jo\"" Stromboli flavored with Mozzarella, Ham,… Unknown     
    ## 4      2       4 "\"Jo\"" Lavender Biscuits                         Blueberry M…
    ## 5      2       5 "\"Jo\"" Salmon and Asparagus Pie                  Apple and R…
    ## 6      2       6 "\"Jo\"" Rum and Raisin Baked Cheesecake           Limoncello …
    ## 7      2       7 "\"Jo\"" Raspberry & Strawberry Mousse Cake        Pain Aux Ra…
    ## 8      2       8 "\"Jo\"" Raspberry and Blueberry Mille Feuille     Mini Victor…

``` r
anti_join(bakers_df, results_df, by = c("series", "baker"))
```

    ## # A tibble: 1 × 6
    ##   baker_name  series baker_age baker_occupation hometown     baker
    ##   <chr>        <dbl>     <dbl> <chr>            <chr>        <chr>
    ## 1 Jo Wheatley      2        41 Housewife        Ongar, Essex Jo

``` r
anti_join(results_df, bakers_df, by = c("series", "baker"))
```

    ## # A tibble: 8 × 5
    ##   series episode baker  technical result    
    ##    <dbl>   <dbl> <chr>      <dbl> <chr>     
    ## 1      2       1 Joanne        11 IN        
    ## 2      2       2 Joanne        10 IN        
    ## 3      2       3 Joanne         1 IN        
    ## 4      2       4 Joanne         8 IN        
    ## 5      2       5 Joanne         6 IN        
    ## 6      2       6 Joanne         1 STAR BAKER
    ## 7      2       7 Joanne         3 IN        
    ## 8      2       8 Joanne         1 WINNER

create a single dataset

``` r
merged_df = bakes_df |>
  full_join(bakers_df, by = c("baker" = "baker", "series" = "series")) |> 
  full_join(results_df, by = c("baker" = "baker", "series" = "series", "episode" = "episode")) |> 
  select(baker,everything())
merged_df
```

    ## # A tibble: 1,170 × 11
    ##    baker     series episode signature_bake     show_stopper baker_name baker_age
    ##    <chr>      <dbl>   <dbl> <chr>              <chr>        <chr>          <dbl>
    ##  1 Annetha        1       1 "Light Jamaican B… Red, White … Annetha M…        30
    ##  2 David          1       1 "Chocolate Orange… Black Fores… David Cha…        31
    ##  3 Edd            1       1 "Caramel Cinnamon… N/A          Edd Kimber        24
    ##  4 Jasminder      1       1 "Fresh Mango and … N/A          Jasminder…        45
    ##  5 Jonathan       1       1 "Carrot Cake with… Three Tiere… Jonathan …        25
    ##  6 Lea            1       1 "Cranberry and Pi… Raspberries… Lea Harris        51
    ##  7 Louise         1       1 "Carrot and Orang… Never Fail … Louise Br…        44
    ##  8 Mark           1       1 "Sticky Marmalade… Heart-shape… Mark Whit…        48
    ##  9 Miranda        1       1 "Triple Layered B… Three Tiere… Miranda B…        37
    ## 10 Ruth           1       1 "Three Tiered Lem… Classic Cho… Ruth Clem…        31
    ## # ℹ 1,160 more rows
    ## # ℹ 4 more variables: baker_occupation <chr>, hometown <chr>, technical <dbl>,
    ## #   result <chr>

export as csv

``` r
write_csv(merged_df, "data/gbb_datasets/merged_data.csv")
head(merged_df)
```

    ## # A tibble: 6 × 11
    ##   baker     series episode signature_bake      show_stopper baker_name baker_age
    ##   <chr>      <dbl>   <dbl> <chr>               <chr>        <chr>          <dbl>
    ## 1 Annetha        1       1 Light Jamaican Bla… Red, White … Annetha M…        30
    ## 2 David          1       1 Chocolate Orange C… Black Fores… David Cha…        31
    ## 3 Edd            1       1 Caramel Cinnamon a… N/A          Edd Kimber        24
    ## 4 Jasminder      1       1 Fresh Mango and Pa… N/A          Jasminder…        45
    ## 5 Jonathan       1       1 Carrot Cake with L… Three Tiere… Jonathan …        25
    ## 6 Lea            1       1 Cranberry and Pist… Raspberries… Lea Harris        51
    ## # ℹ 4 more variables: baker_occupation <chr>, hometown <chr>, technical <dbl>,
    ## #   result <chr>

Data cleaning process: I first import these three datasets and
standardize their names. Because the `baker_name` in the `bakers_df` is
the full name and the `baker` in other three datasets are the first
name, so I generate a new variable also called `baker` in the
`bakers_df` for convenience and future merge. And while import the
`results_df`, there are two unnecessary lines before the data, so I
skipped those two rows. For merging these three data frame, I used the
variable `baker` and `series` as the benchmark and delete the `baker`
because we already have `baker_name`. After merging, I put the
`baker_name` in the first column for a clearer view.

The final dataset includes key information and variables such as their
name by `baker_name`, the series and episodes they participated by
`series` and `episodes` and the competition results by `result`.
Additionally, there are also some main information of the baker such as
their age by `baker_age`, their job by`baker_occupation` and their home
town by `hometown`.

## star baker or winner of each episode in Seasons 5 through 10.

``` r
star_bakers_and_winners = merged_df |> 
  filter(result == "STAR BAKER" | result == "WINNER") |> 
  filter(series >= 5 & series <= 10) |> 
  select(baker, series, episode, result)
view(star_bakers_and_winners)
```

It’s surprising that in series 5 and 10, although Nancy and David only
won the STAR BAKER once but still won the final competition.For series 6
to 9, it’s predictable because all final winners was awarded at least
two times in each series.

## viewership

Import, clean, tidy, and organize the viewership data in viewership.csv.
Show the first 10 rows of this dataset. What was the average viewership
in Season 1? In Season 5?

``` r
viewership =
  read_csv("data/gbb_datasets/viewers.csv") |> 
  janitor::clean_names() |> 
  mutate(episode = as.numeric(episode)) |> 
  mutate(across(starts_with("series"), ~as.numeric(.)))
```

    ## Rows: 10 Columns: 11
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (11): Episode, Series 1, Series 2, Series 3, Series 4, Series 5, Series ...
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
head(viewership)
```

    ## # A tibble: 6 × 11
    ##   episode series_1 series_2 series_3 series_4 series_5 series_6 series_7
    ##     <dbl>    <dbl>    <dbl>    <dbl>    <dbl>    <dbl>    <dbl>    <dbl>
    ## 1       1     2.24     3.1      3.85     6.6      8.51     11.6     13.6
    ## 2       2     3        3.53     4.6      6.65     8.79     11.6     13.4
    ## 3       3     3        3.82     4.53     7.17     9.28     12.0     13.0
    ## 4       4     2.6      3.6      4.71     6.82    10.2      12.4     13.3
    ## 5       5     3.03     3.83     4.61     6.95     9.95     12.4     13.1
    ## 6       6     2.75     4.25     4.82     7.32    10.1      12       13.1
    ## # ℹ 3 more variables: series_8 <dbl>, series_9 <dbl>, series_10 <dbl>

``` r
avg_viewership_s1 = mean(pull(viewership, `series_1`), na.rm = TRUE)
avg_viewership_s5 = mean(pull(viewership, `series_5`), na.rm = TRUE)

avg_viewership_s1
```

    ## [1] 2.77

``` r
avg_viewership_s5
```

    ## [1] 10.0393

The average viewership in Season 1 is 2.77, and is 10.04 in Season 5.
